{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C://Users//jeickmeyer//Development//GIT//anomalieerkennung-am-temper//Hackathon2023//Submissions//DasKollektiv\\2023_03_17_data_pred.pq\n",
      "C://Users//jeickmeyer//Development//GIT//anomalieerkennung-am-temper//Hackathon2023//Submissions//DasKollektiv\\2023_03_24_data_pred.pq\n",
      "C://Users//jeickmeyer//Development//GIT//anomalieerkennung-am-temper//Hackathon2023//Submissions//DasKollektiv\\2023_03_31_data_pred.pq\n",
      "C://Users//jeickmeyer//Development//GIT//anomalieerkennung-am-temper//Hackathon2023//Submissions//DasKollektiv\\2023_04_14_data_pred.pq\n",
      "C://Users//jeickmeyer//Development//GIT//anomalieerkennung-am-temper//Hackathon2023//Submissions//DasKollektiv\\2023_04_18_data_pred.pq\n",
      "\n",
      "[27.0, 63.0, 29.0, 1.0, 16.0]\tTotal: 136.0/1000 (13.6%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob, pathlib\n",
    "\n",
    "def get_final_score(Y_pred, Y_real, verbose:bool=False):\n",
    "  # ------------------------------------------ #\n",
    "  if type(Y_pred) == pd.DataFrame:\n",
    "    Y_pred = Y_pred.values\n",
    "  if type(Y_real) == pd.DataFrame:\n",
    "    Y_real = Y_real.values\n",
    "\n",
    "  res_a = np.abs(Y_real-Y_pred)\n",
    "\n",
    "  total = len(res_a)\n",
    "  u_05 = np.sum(res_a <= 0.05)\n",
    "  u_05_p = np.round(100 * (u_05 / total), 2)\n",
    "\n",
    "  u_10 = np.sum(res_a <= 0.10) - u_05\n",
    "  u_10_p = np.round(100 * (u_10 / total), 2)\n",
    "\n",
    "  u_50 = np.sum(res_a <= 0.50) - u_05 - u_10\n",
    "  u_50_p = np.round(100 * (u_50 / total), 2)\n",
    "\n",
    "  high = np.sum(res_a > 0.50)\n",
    "  high_p = np.round(100 * (high / total), 2)\n",
    "  \n",
    "  # ------------------------------------------ #\n",
    "  bool_array = res_a > 0.1\n",
    "  # Finden Sie die Indizes der Übergänge von False zu True\n",
    "  transitions = np.where(np.diff(bool_array))[0] + 1\n",
    "  # Teilen Sie das Array in zusammenhängende Blöcke\n",
    "  blocks = np.split(bool_array, transitions)\n",
    "  # Filtern Sie nur die Blöcke mit True-Werten\n",
    "  true_blocks = [block for block in blocks if block[0]]\n",
    "  \n",
    "  single_blocks=0\n",
    "  short_blocks=0\n",
    "  long_blocks=0\n",
    "\n",
    "  for block in true_blocks:\n",
    "    if len(block) < 2:\n",
    "      single_blocks+=1\n",
    "    elif len(block) >= 2 and len(block) < 10:\n",
    "      short_blocks+=1\n",
    "    else:\n",
    "      long_blocks+=1\n",
    "\n",
    "  # general_block_score = np.round(100*(1.0 - (len(true_blocks) / (total/2))), 2)\n",
    "  general_block_score = u_05_p\n",
    "  single_block_score = np.round(100*((single_blocks / (total))), 2)\n",
    "  short_block_score = np.round(100*((short_blocks / (total))), 2)\n",
    "  # ------------------------------------------ #\n",
    "  total_error_score = u_05_p + (u_10_p/2) + (u_50_p/4)\n",
    "  total_block_score = general_block_score + (single_block_score/2) + (short_block_score/4)\n",
    "\n",
    "  if verbose: \n",
    "    print(f'  0 - .05: {u_05_p}%')\n",
    "    print(f'.05 - .1: {u_10_p}%')\n",
    "    print(f'.10 - .5: {u_50_p}%')\n",
    "    print(f'Higher .50: {high_p}% \\n')\n",
    "    print(f'Single outlierblocks: {single_blocks}')\n",
    "    print(f'Short outlierblocks: {short_blocks}')\n",
    "    print(f'Long outlierblocks: {long_blocks}')\n",
    "    print(f'----- Scores -----')\n",
    "    print(f'Error Scores:')\n",
    "    print(f'0 - .05 deviation score: {np.round(u_05_p, 4)}')\n",
    "    print(f'.05 - .1 deviation score: {np.round(u_10_p/2, 4)}')\n",
    "    print(f'.1 - .5 deviation score: {np.round(u_50_p/4, 4)}')\n",
    "    print(f'Total error score: {total_error_score}')\n",
    "    print(f'Block Scores:')\n",
    "    print(f'General score for less block: {general_block_score}')\n",
    "    print(f'Single outliers score: {single_block_score/2}')\n",
    "    print(f'Short outliers score: {short_block_score/4}')\n",
    "    print(f'Total block score: {total_block_score}')\n",
    "    print('----- ----- ----- ----- -----')\n",
    "  \n",
    "  return np.round(total_error_score + total_block_score, 0)\n",
    "\n",
    "# def find_originals():\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "  eval_path='C://Users//jeickmeyer//Development//GIT//anomalieerkennung-am-temper//Hackathon2023//Submissions//DasKollektiv//'\n",
    "  # eval_path='C://Users//jeickmeyer//Development//GIT//anomalieerkennung-am-temper//Hackathon2023//Data_Jury//'\n",
    "  ref_path='C://Users//jeickmeyer//Development//GIT//anomalieerkennung-am-temper//Hackathon2023//Data_Jury//Y'\n",
    "\n",
    "  references_list = []\n",
    "\n",
    "  pred_score_list = []\n",
    "  xg_score_list = []\n",
    "  nn_score_list = []\n",
    "\n",
    "  for file in glob.glob(eval_path+'**'):\n",
    "    if '_pred' in file and '.pq' in file:\n",
    "      print(file)\n",
    "      _ = ref_path+'//'+str(pathlib.Path(file).name).replace('_pred', '')\n",
    "      if 'data' in _:\n",
    "        _ = _.replace('data', 'target')\n",
    "      pred_y = pd.read_parquet(file)\n",
    "      real_y = pd.read_parquet(_)\n",
    "      # print(f'\\nMatching\\n\\tPrediction:\\t{file}\\n\\tOriginal:\\t{_}')\n",
    "      score = get_final_score(pred_y, real_y)\n",
    "      pred_score_list.append(score)\n",
    "    \n",
    "    # if '_XG' in file:\n",
    "    #   _ = ref_path+'//'+str(pathlib.Path(file).name).replace('_XG', '')\n",
    "    #   if 'data' in _:\n",
    "    #     _ = _.replace('data', 'target')\n",
    "    #   pred_y = pd.read_parquet(file)\n",
    "    #   real_y = pd.read_parquet(_)\n",
    "    #   # print(f'\\nMatching\\n\\tPrediction:\\t{file}\\n\\tOriginal:\\t{_}')\n",
    "    #   score = get_final_score(pred_y, real_y)\n",
    "    #   xg_score_list.append(score)\n",
    "    \n",
    "    # if '_NN' in file:\n",
    "    #   _ = ref_path+'//'+str(pathlib.Path(file).name).replace('_NN', '')\n",
    "    #   if 'data' in _:\n",
    "    #     _ = _.replace('data', 'target')\n",
    "    #   pred_y = pd.read_parquet(file)\n",
    "    #   real_y = pd.read_parquet(_)\n",
    "    #   # print(f'\\nMatching\\n\\tPrediction:\\t{file}\\n\\tOriginal:\\t{_}')\n",
    "    #   score = get_final_score(pred_y, real_y)\n",
    "    #   nn_score_list.append(score)\n",
    "\n",
    "print(f'\\n{pred_score_list}\\tTotal: {np.sum(pred_score_list)}/{len(pred_score_list)*200} ({round(100*(np.sum(pred_score_list)/(len(pred_score_list)*200)), 2)}%)')\n",
    "# print(f'\\n{xg_score_list}\\tTotal: {np.sum(xg_score_list)}/{len(xg_score_list)*200} ({round(100*(np.sum(xg_score_list)/(len(xg_score_list)*200)), 2)}%)')\n",
    "# print(f'\\n{nn_score_list}\\tTotal: {np.sum(nn_score_list)}/{len(nn_score_list)*200} ({round(100*(np.sum(nn_score_list)/(len(nn_score_list)*200)), 2)}%)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
